{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficiency of an algorithm can be analyzed at two different stages, before implementation and after implementation. They are the following −\n",
    "\n",
    "A Priori Analysis − This is a theoretical analysis of an algorithm. Efficiency of an algorithm is measured by assuming that all other factors, for example, processor speed, are constant and have no effect on the implementation.\n",
    "\n",
    "A Posterior Analysis − This is an empirical analysis of an algorithm. The selected algorithm is implemented using programming language. This is then executed on target computer machine. In this analysis, actual statistics like running time and space required, are collected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose X is an algorithm and n is the size of input data, the time and space used by the algorithm X are the two main factors, which decide the efficiency of X.\n",
    "\n",
    "Time Factor − Time is measured by counting the number of key operations such as comparisons in the sorting algorithm.\n",
    "\n",
    "Space Factor − Space is measured by counting the maximum memory space required by the algorithm.\n",
    "\n",
    "The complexity of an algorithm f(n) gives the running time and/or the storage space required by the algorithm in terms of n as the size of input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Space Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Space complexity of an algorithm represents the amount of memory space required by the algorithm in its life cycle. The space required by an algorithm is equal to the sum of the following two components −\n",
    "\n",
    "A fixed part that is a space required to store certain data and variables, that are independent of the size of the problem. For example, simple variables and constants used, program size, etc.\n",
    "\n",
    "A variable part is a space required by variables, whose size depends on the size of the problem. For example, dynamic memory allocation, recursion stack space, etc.\n",
    "\n",
    "Space complexity S(P) of any algorithm P is S(P) = C + SP(I), where C is the fixed part and S(I) is the variable part of the algorithm, which depends on instance characteristic I. Following is a simple example that tries to explain the concept −\n",
    "\n",
    "Algorithm: SUM(A, B)\n",
    "\n",
    "Step 1 -  START\n",
    "\n",
    "Step 2 -  C ← A + B + 10\n",
    "\n",
    "Step 3 -  Stop\n",
    "\n",
    "Here we have three variables A, B, and C and one constant. Hence S(P) = 1 + 3. Now, space depends on data types of given variables and constant types and it will be multiplied accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity of an algorithm represents the amount of time required by the algorithm to run to completion. Time requirements can be defined as a numerical function T(n), where T(n) can be measured as the number of steps, provided each step consumes constant time.\n",
    "\n",
    "For example, addition of two n-bit integers takes n steps. Consequently, the total computational time is T(n) = c ∗ n, where c is the time taken for the addition of two bits. Here, we observe that T(n) grows linearly as the input size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) Asymptotic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Asymptotic Analysis, the performance of an algorithm is evaluated in terms of input size. Here, how the time (or space) taken by an algorithm increases with the input size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asymptotic Analysis is not perfect, but that’s the best way available for analyzing algorithms. For example, say there are two sorting algorithms that take 1000nLogn and 2nLogn time respectively on a machine. Both of these algorithms are asymptotically same (order of growth is nLogn). So, With Asymptotic Analysis, we can’t judge which one is better as we ignore constants in Asymptotic Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) Analysis of Algorithms (Worst, Average and Best Cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Search and its analsis by using Asymptotic analysis. We can have three cases to analyze an algorithm: \n",
    "\n",
    "1) The Worst Case \n",
    "\n",
    "2) Average Case \n",
    "\n",
    "3) Best Case\n",
    "\n",
    "Let us consider the following implementation of Linear Search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 is present at index 2\n"
     ]
    }
   ],
   "source": [
    "def search(arr, x): \n",
    "    for index, value in enumerate(arr): \n",
    "        if value == x: \n",
    "            return index \n",
    "    return -1\n",
    "  \n",
    "arr = [1, 10, 30, 15] \n",
    "x = 30\n",
    "print(\"{0} is present at index {1}\".format(x,search(arr, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst Case Analysis:\n",
    "\n",
    "For Linear Search, the worst case happens when the element to be searched (x in the above code) is not present in the array that causesthe upper bound on running time of an algorithm. When x is not present, the search() functions compares it with all the elements of arr[] one by one. Therefore, the worst case time complexity of linear search would be Θ(n).\n",
    "\n",
    "Average Case Analysis:\n",
    "\n",
    "In average case analysis, we take all possible inputs and calculate computing time for all of the inputs. Sum all the calculated values and divide the sum by total number of inputs. We must know (or predict) distribution of cases. For the linear search problem, let us assume that all cases are uniformly distributed (including the case of x not being present in array). So we sum all the cases and divide the sum by (n+1). \n",
    "\n",
    "\n",
    "Best Case Analysis:\n",
    "\n",
    "In the best case analysis, we calculate lower bound on running time of an algorithm. We must know the case that causes minimum number of operations to be executed. In the linear search problem, the best case occurs when x is present at the first location. \n",
    "\n",
    "we do worst case analysis to analyze algorithms. In the worst analysis, we guarantee an upper bound on the running time of an algorithm which is good information. \n",
    "The average case analysis is not easy to do in most of the practical cases and it is rarely done. In the average case analysis, we must know (or predict) the mathematical distribution of all possible inputs. \n",
    "The Best Case analysis is bogus. Guaranteeing a lower bound on an algorithm doesn’t provide any information as in the worst case, an algorithm may take years to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Θ Notation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Θ(g(n))  = {f(n): there exist positive constants c1, c2 and n0 such that 0 <= c1*g(n) <= f(n) <= c2*g(n) for all n >= n0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above definition means, if f(n) is theta of g(n), then the value f(n) is always between c1*g(n) and c2*g(n) for large values of n (n >= n0). The definition of theta also requires that f(n) must be non-negative for values of n greater than n0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big O Notation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Big O notation defines an upper bound of an algorithm, it bounds a function only from above. For example, consider the case of Insertion Sort. It takes linear time in best case and quadratic time in worst case. We can safely say that the time complexity of Insertion sort is O(n^2). Note that O(n^2) also covers linear time. \n",
    "If we use Θ notation to represent time complexity of Insertion sort, we have to use two statements for best and worst cases: \n",
    "1. The worst case time complexity of Insertion Sort is Θ(n^2). \n",
    "2. The best case time complexity of Insertion Sort is Θ(n). \n",
    "\n",
    "The Big O notation is useful when we only have upper bound on time complexity of an algorithm. Many times we easily find an upper bound by simply looking at the algorithm.  \n",
    "\n",
    "O(g(n)) = { f(n): there exist positive constants c and \n",
    "                  n0 such that 0 <= f(n) <= c*g(n) for \n",
    "                  all n >= n0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ω Notation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as Big O notation provides an asymptotic upper bound on a function, Ω notation provides an asymptotic lower bound. \n",
    "Ω Notation can be useful when we have lower bound on time complexity of an algorithm. As discussed in the previous post, the best case performance of an algorithm is generally not useful, the Omega notation is the least used notation among all three. \n",
    "\n",
    "For a given function g(n), we denote by Ω(g(n)) the set of functions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ω (g(n)) = {f(n): there exist positive constants c and n0 such that 0 <= c*g(n) <= f(n) for all n >= n0}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties of Asymptotic Notations : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we have gone through the definition of this three notations let’s now discuss some important properties of those notations. \n",
    "\n",
    "1. General Properties : \n",
    "\n",
    "     If f(n) is O(g(n)) then a*f(n) is also O(g(n)) ; where a is a constant. \n",
    "\n",
    "     Example: f(n) = 2n²+5 is O(n²) \n",
    "     then 7*f(n) = 7(2n²+5) = 14n²+35 is also O(n²) .\n",
    "\n",
    "     Similarly this property satisfies for both Θ and Ω notation. \n",
    " \n",
    "\n",
    "     We can say \n",
    "     If f(n) is Θ(g(n)) then a*f(n) is also Θ(g(n)) ; where a is a constant. \n",
    "     If f(n) is Ω (g(n)) then a*f(n) is also Ω (g(n)) ; where a is a constant.\n",
    "\n",
    "2. Transitive Properties : \n",
    "\n",
    "    If f(n) is O(g(n)) and g(n) is O(h(n)) then f(n) = O(h(n)) .\n",
    "\n",
    "    Example: if f(n) = n, g(n) = n² and h(n)=n³\n",
    "    n is O(n²) and n² is O(n³)\n",
    "    then n is O(n³)\n",
    "\n",
    "\n",
    "\n",
    "   Similarly this property satisfies for both Θ and Ω notation.\n",
    "\n",
    "   We can say\n",
    "   If f(n) is Θ(g(n)) and g(n) is Θ(h(n)) then f(n) = Θ(h(n)) .\n",
    "   If f(n) is Ω (g(n)) and g(n) is Ω (h(n)) then f(n) = Ω (h(n))\n",
    "\n",
    "3. Reflexive Properties : \n",
    "\n",
    "      Reflexive properties are always easy to understand after transitive.\n",
    "\n",
    "      If f(n) is given then f(n) is O(f(n)). Since MAXIMUM VALUE OF f(n) will be f(n) ITSELF !\n",
    "\n",
    "      Hence x = f(n) and y = O(f(n) tie themselves in reflexive relation always.\n",
    "\n",
    "      Example: f(n) = n² ; O(n²) i.e O(f(n))\n",
    "\n",
    "      Similarly this property satisfies for both Θ and Ω notation.\n",
    "\n",
    "      We can say that:\n",
    "\n",
    "      If f(n) is given then f(n) is Θ(f(n)).\n",
    "\n",
    "      If f(n) is given then f(n) is Ω (f(n)).\n",
    "\n",
    "4. Symmetric Properties : \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "      If f(n) is Θ(g(n)) then g(n) is Θ(f(n)) . \n",
    " \n",
    "\n",
    "      Example: f(n) = n² and g(n) = n² \n",
    "      then f(n) = Θ(n²) and g(n) = Θ(n²) \n",
    " \n",
    "\n",
    "      This property only satisfies for Θ notation.\n",
    "\n",
    "5. Transpose Symmetric Properties : \n",
    " \n",
    "\n",
    "      If f(n) is O(g(n)) then g(n) is Ω (f(n)). \n",
    " \n",
    "\n",
    "      Example: f(n) = n , g(n) = n² \n",
    "      then n is O(n²) and n² is Ω (n) \n",
    "\n",
    "This property only satisfies for O and Ω notations.\n",
    "\n",
    "6. Some More Properties : \n",
    "\n",
    "     1.) If f(n) = O(g(n)) and f(n) = Ω(g(n)) then f(n) = Θ(g(n))\n",
    "\n",
    "     2.) If f(n) = O(g(n)) and d(n)=O(e(n)) \n",
    "          then f(n) + d(n) = O( max( g(n), e(n) )) \n",
    "          Example: f(n) = n i.e O(n) \n",
    "                         d(n) = n² i.e O(n²) \n",
    "                         then f(n) + d(n) = n + n² i.e O(n²)\n",
    "\n",
    "\n",
    "\n",
    "      3.) If f(n)=O(g(n)) and d(n)=O(e(n)) \n",
    "           then f(n) * d(n) = O( g(n) * e(n) ) \n",
    "           Example: f(n) = n i.e O(n) \n",
    "           d(n) = n² i.e O(n²) \n",
    "                      then f(n) * d(n) = n * n² = n³ i.e O(n³)\n",
    "\n",
    "\n",
    "\n",
    "There are two more notations called little o and little omega. Little o provides strict upper bound (equality condition is removed from Big O) and little omega provides strict lower bound (equality condition removed from big omega)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Algorithms (Analysis of Loops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of iterative programs with simple examples is discussed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O(1): Time complexity of a function (or set of statements) is considered as O(1) if it doesn’t contain loop, recursion and call to any other non-constant time function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex:\n",
    "\n",
    "For example swap valaues is considered O(1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n",
      "3 2\n"
     ]
    }
   ],
   "source": [
    "#Example of swap:\n",
    "    \n",
    "a = 2\n",
    "\n",
    "b = 3\n",
    "\n",
    "print(a,b)\n",
    "\n",
    "b,a = a,b\n",
    "\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loop or recursion that runs a constant number of times is also considered as O(1). For example the following loop is O(1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 times\n",
      "1 times\n",
      "2 times\n",
      "3 times\n",
      "4 times\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "\n",
    "x = 5 \n",
    "for i in range(x):\n",
    "    print(\"{0} times\".format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(start, stop, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O(n): Time Complexity of a loop is considered as O(n) if the loop variables is incremented / decremented by a constant amount. For example following functions have O(n) time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 times\n",
      "2 times\n",
      "4 times\n",
      "6 times\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "# here n = 2\n",
    "x = 7\n",
    "for i in range(0,x,2):\n",
    "    print(\"{0} times\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 times\n",
      "18 times\n",
      "15 times\n",
      "12 times\n",
      "9 times\n",
      "6 times\n",
      "3 times\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "# Here n =-3\n",
    "x = 21\n",
    "for i in range(x,0,-3):\n",
    "    print(\"{0} times\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O(nc): Time complexity of nested loops is equal to the number of times the innermost statement is executed. For example the following sample loops have O(n2) time complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example Selection sort and Insertion Sort have O(n2) time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
